{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b327ee0-b1f5-4eae-a208-92abe2938813",
   "metadata": {},
   "source": [
    "# DSCI 551 Project: File System & Analysis on COVID-19 Vaccination Rates\n",
    "Gordon Su, Lucas Huang  \n",
    "Section 32414 (Afternoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa86f4-e15a-4680-a7ff-fced18b6f1b6",
   "metadata": {},
   "source": [
    "Date range: 2020-12-02 to 2022-03-29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beefaef-9865-47a3-a185-209113a4bc6c",
   "metadata": {},
   "source": [
    "### All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4deb6413-9b50-48fb-9dc5-aab914dc8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import firebase_admin\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from firebase_admin import db\n",
    "from firebase_admin import credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39583b21-026f-44af-a4ca-68e9767c59d3",
   "metadata": {},
   "source": [
    "### Import and preview vaccination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e1c5261-e8b3-4fc5-b0ad-344039987897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>daily_vaccinations_raw</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  daily_vaccinations_raw  year  month  day\n",
       "0  Afghanistan                     NaN  2021      2   22\n",
       "1  Afghanistan                     NaN  2021      2   23\n",
       "2  Afghanistan                     NaN  2021      2   24"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_df = pd.read_csv('./data/country_vaccinations.csv')\n",
    "vacc_df['date'] = pd.to_datetime(vacc_df['date'])\n",
    "vacc_df['year'] = vacc_df.apply(lambda row: row.date.year, axis=1)\n",
    "vacc_df['month'] = vacc_df.apply(lambda row: row.date.month, axis=1)\n",
    "vacc_df['day'] = vacc_df.apply(lambda row: row.date.day, axis=1)\n",
    "\n",
    "vacc_cols_to_drop = ['date', 'iso_code', 'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', \n",
    "                'daily_vaccinations', 'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred', \n",
    "                'people_fully_vaccinated_per_hundred', 'daily_vaccinations_per_million', 'vaccines', \n",
    "                'source_name', 'source_website']\n",
    "vacc_df = vacc_df.drop(vacc_cols_to_drop, axis=1)\n",
    "vacc_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a853313-d63e-48b5-ad38-8c8a9dd87cb6",
   "metadata": {},
   "source": [
    "### Import and preview PFE price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "441f8d21-aa3f-4f1b-a698-360b66dcb796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.354626</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.687180</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.922195</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adj Close  year  month  day\n",
       "0  38.354626  2020     12    2\n",
       "1  37.687180  2020     12    3\n",
       "2  37.922195  2020     12    4"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfe_prices_df = pd.read_csv('./data/PFE_historical_prices.csv')\n",
    "pfe_prices_df['Date'] = pd.to_datetime(pfe_prices_df['Date'])\n",
    "pfe_prices_df['year'] = pfe_prices_df.apply(lambda row: row.Date.year, axis=1)\n",
    "pfe_prices_df['month'] = pfe_prices_df.apply(lambda row: row.Date.month, axis=1)\n",
    "pfe_prices_df['day'] = pfe_prices_df.apply(lambda row: row.Date.day, axis=1)\n",
    "\n",
    "pfe_cols_to_drop = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "pfe_prices_df = pfe_prices_df.drop(pfe_cols_to_drop, axis=1)\n",
    "pfe_prices_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f99ef-472d-4b93-a51f-69271238951c",
   "metadata": {},
   "source": [
    "### Convert vaccination dataframe into json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5babd45b-bbb9-402f-ae3a-8bf7a165e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_countries = ['Australia', 'Belgium', 'Canada', 'France', 'Germany', 'Italy', 'Japan', 'Switzerland', 'United Kingdom', 'United States']\n",
    "selected_countries_json_files = []\n",
    "all_years = [2020, 2021, 2022]\n",
    "all_months = [month for month in range(1, 13)]\n",
    "\n",
    "for country in selected_countries:\n",
    "    country_df = vacc_df.loc[vacc_df['country'] == country]\n",
    "    country_dict = {}\n",
    "    \n",
    "    for year in all_years:\n",
    "        year_df = vacc_df.loc[vacc_df['year'] == year]\n",
    "        year_dict = {}\n",
    "        \n",
    "        for month in all_months:\n",
    "            month_df = vacc_df.loc[vacc_df['month'] == month]\n",
    "            month_dict = dict(month_df[['day', 'daily_vaccinations_raw']].values)\n",
    "            month_dict = {int(k):(0 if math.isnan(v) else int(v)) for k,v in month_dict.items()}\n",
    "            \n",
    "            year_dict[month] = month_dict\n",
    "        country_dict[year] = year_dict\n",
    "    \n",
    "    file_name = './data/' + country + '_vaccinations.json'\n",
    "    selected_countries_json_files.append(file_name)\n",
    "    \n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(country_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3800c97-ec4b-4aa9-ba00-a5bf818e57b1",
   "metadata": {},
   "source": [
    "### Convert PFE dataframe into json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3795eca1-3887-4f25-9d0d-33431b05f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years = [2020, 2021, 2022]\n",
    "all_months = [month for month in range(1, 13)]\n",
    "\n",
    "pfe_dict = {}\n",
    "    \n",
    "for year in all_years:\n",
    "    year_df = pfe_prices_df.loc[pfe_prices_df['year'] == year]\n",
    "    year_dict = {}\n",
    "\n",
    "    for month in all_months:\n",
    "        month_df = pfe_prices_df.loc[pfe_prices_df['month'] == month]\n",
    "        month_dict = dict(month_df[['day', 'Adj Close']].values)\n",
    "        month_dict = {int(k):(0 if math.isnan(v) else float(v)) for k,v in month_dict.items()}\n",
    "\n",
    "        year_dict[month] = month_dict\n",
    "    pfe_dict[year] = year_dict\n",
    "\n",
    "pfe_file_name = './data/PFE_historical_prices.json'\n",
    "\n",
    "with open(pfe_file_name, 'w') as json_file:\n",
    "    json.dump(pfe_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc989957",
   "metadata": {},
   "source": [
    "### EDFS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535b20b-e846-48a3-9f78-8e069d76741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate('./dsci-551-3cb2b-firebase-adminsdk-7ajia-c0dffd1d3c.json')\n",
    "databaseURL = 'https://dsci-551-3cb2b-default-rtdb.firebaseio.com/'\n",
    "default_app = firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': databaseURL\n",
    "})\n",
    "ref = db.reference('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "80d5c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help\n",
    "def edfs_help():\n",
    "    print('''\\033[1m\\033[4mFunctions:\\033[0m\\033[0m\n",
    "    \\033[1mremove_file(path)\\033[0m \\t\\t\\t Usage example: remove_file('/test/test.json')\n",
    "    \\033[1mremove_directory(path)\\033[0m \\t\\t Usage example: remove_directory('/test/')\n",
    "    \\033[1mcat_file(path)\\033[0m \\t\\t\\t Usage example: cat_file('/test/test.json')\n",
    "    \\033[1mlist_contents(path)\\033[0m \\t\\t Usage example: list_contents('/test/')\n",
    "    \\033[1mmake_directory(path)\\033[0m \\t\\t Usage example: make_directory('/test/')\n",
    "    \\033[1mput_file(file, path)\\033[0m \\t\\t Usage example: put_file('test.json', '/test/')\n",
    "    \\033[1mgetPartitionLocations(file_path)\\033[0m \\t\\t Usage example: getPartitionLocations('/test/test.json')\n",
    "    \\033[1mreadPartition(file_path, partition_num)\\033[0m \\t\\t Usage example: readPartition('/test/test.json', 1)''')\n",
    "\n",
    "# rm\n",
    "def remove_file(path):\n",
    "    splitPath = os.path.splitext(path)\n",
    "    \n",
    "    # Remove file metadata\n",
    "    metadata_ref = db.reference(splitPath[0] + splitPath[1].replace('.', ' '))\n",
    "    children = metadata_ref.get()\n",
    "    if children == None:\n",
    "        print('File does not exist')\n",
    "        return\n",
    "    for key, value in children.items():\n",
    "        metadata_ref.child(key).set({})\n",
    "        \n",
    "    # Remove file partition contents\n",
    "    partition_contents_ref = db.reference('/partitions' + splitPath[0] + splitPath[1].replace('.', ' '))\n",
    "    children = partition_contents_ref.get()\n",
    "    if children != None:\n",
    "        for key, value in children.items():\n",
    "            partition_contents_ref.child(key).set({})\n",
    "    \n",
    "    parent_dir_path = path[:path.rfind('/')]\n",
    "    \n",
    "    # Parent directory is now empty\n",
    "    metadata_parent_ref = db.reference(parent_dir_path)\n",
    "    children = metadata_parent_ref.get()\n",
    "    if children == None:\n",
    "        print('Directory empty')\n",
    "        \n",
    "        # Set new path for metadata\n",
    "        metadata_parent_ref.set({\n",
    "            'New Path':\n",
    "            {\n",
    "                'New_Path': True\n",
    "            }})\n",
    "\n",
    "        # Set new path for partition contents\n",
    "        partition_contents_parent_ref = db.reference('/partitions' + parent_dir_path)\n",
    "        partition_contents_parent_ref.set({\n",
    "            'New Path':\n",
    "            {\n",
    "                'New_Path': True\n",
    "            }})\n",
    "        \n",
    "# rm directory\n",
    "def remove_directory(path):\n",
    "    # Remove metadata directory\n",
    "    metadata_ref = db.reference(path)\n",
    "    children = metadata_ref.get()\n",
    "    if children == None:\n",
    "        print('Directory does not exist')\n",
    "        return\n",
    "    for key, value in children.items():\n",
    "        metadata_ref.child(key).set({})\n",
    "        \n",
    "    # Remove partition contents directory\n",
    "    partition_contents_ref = db.reference('/partitions' + path)\n",
    "    children = partition_contents_ref.get()\n",
    "    if children != None:\n",
    "        for key, value in children.items():\n",
    "            partition_contents_ref.child(key).set({})\n",
    "\n",
    "# cat\n",
    "def cat_file(path):\n",
    "    splitPath = os.path.splitext(path)\n",
    "    metadata_ref = db.reference(splitPath[0] + splitPath[1].replace('.', ' '))\n",
    "    contents = metadata_ref.get()\n",
    "    if contents == None:\n",
    "        print('File does not exist')\n",
    "        return\n",
    "    for key, value in contents.items():\n",
    "        partition_ref = db.reference(value['location'])\n",
    "        partition_contents = partition_ref.get()\n",
    "        print(json.dumps(partition_contents, indent=1))\n",
    "\n",
    "# ls\n",
    "def list_contents(path):\n",
    "    ref = db.reference(path)\n",
    "    contents = ref.get()\n",
    "    if contents == None:\n",
    "        print('Directory does not exist')\n",
    "        return\n",
    "    for key, val in contents.items():\n",
    "        print(key.replace(' ', '.'))   \n",
    "        \n",
    "# mkdir\n",
    "def make_directory(path):\n",
    "    # Set new path for metadata\n",
    "    metadata_ref = db.reference(path)\n",
    "    metadata_ref.set({\n",
    "        'New Path':\n",
    "        {\n",
    "            'New_Path': True\n",
    "        }})\n",
    "    \n",
    "    # Set new path for partition contents\n",
    "    partition_contents_ref = db.reference('/partitions' + path)\n",
    "    partition_contents_ref.set({\n",
    "        'New Path':\n",
    "        {\n",
    "            'New_Path': True\n",
    "        }})\n",
    "    \n",
    "# put\n",
    "def put_file(file, path):\n",
    "    dir_ref = db.reference(path)\n",
    "    query = dir_ref.child('New Path').get()\n",
    "    if query != None:\n",
    "        dir_ref.child('New Path').set({})\n",
    "        \n",
    "    name_of_file = file.replace('.', ' ')\n",
    "    file_ref = db.reference(path + name_of_file)\n",
    "    \n",
    "    dir_partition_contents_ref = db.reference('/partitions' + path)\n",
    "    query = dir_partition_contents_ref.child('New Path').get()\n",
    "    if query != None:\n",
    "        dir_partition_contents_ref.child('New Path').set({})\n",
    "        \n",
    "    with open('./data/' + file, 'r') as f:\n",
    "        contents = json.load(f)\n",
    "        contents_df = pd.DataFrame(contents.items())\n",
    "        partition_metadata = {}\n",
    "        partition_num = 1\n",
    "        \n",
    "        for index, row in contents_df.iterrows():\n",
    "            year = int(row[0])\n",
    "            year_data = row[1]\n",
    "            months = list(year_data.keys())\n",
    "            months.sort()\n",
    "            \n",
    "            for month in months:\n",
    "                partition_name = 'p' + str(partition_num)\n",
    "                partition_path = '/partitions' + path + name_of_file + '/' + partition_name\n",
    "                partition_ref = db.reference(partition_path)\n",
    "                partition_dict = {}\n",
    "                partition_num += 1\n",
    "                \n",
    "                # Store metadata\n",
    "                metadata = {}\n",
    "                metadata['location'] = partition_path\n",
    "                metadata['year'] = year\n",
    "                metadata['month'] = int(month)\n",
    "                partition_metadata[partition_name] = metadata\n",
    "                \n",
    "                # Store actual contents in partition\n",
    "                for day, value in year_data[month].items():\n",
    "                    partition_dict[day] = value\n",
    "                partition_ref.set(partition_dict)\n",
    "                \n",
    "        partition_metadata['metadata'] = {'num_partitions': partition_num - 1}\n",
    "        file_ref.set(partition_metadata)\n",
    "        \n",
    "# getPartitionLocations (for PMR)\n",
    "def getPartitionData(file_path):\n",
    "    partition_data = []\n",
    "    splitPath = os.path.splitext(file_path)\n",
    "    \n",
    "    metadata_ref = db.reference(splitPath[0] + splitPath[1].replace('.', ' '))\n",
    "    partition_metadata = metadata_ref.get()\n",
    "    num_partitions = partition_metadata['metadata']['num_partitions']\n",
    "    \n",
    "    for partition_num in range(1, num_partitions + 1):\n",
    "        partition_name = 'p' + str(partition_num)\n",
    "        location = partition_metadata[partition_name]['location']\n",
    "        year = partition_metadata[partition_name]['year']\n",
    "        month = partition_metadata[partition_name]['month']\n",
    "        partition_data.append([location, year, month])\n",
    "        \n",
    "    return partition_data\n",
    "    \n",
    "# readPartition (for PMR)\n",
    "def readPartition(partition_content_path):\n",
    "    partition_content_ref = db.reference(partition_content_path)\n",
    "    content = partition_content_ref.get()\n",
    "    content_df = pd.DataFrame(content)\n",
    "    content_df = content_df.fillna(method='ffill')\n",
    "    content_df = content_df.fillna(method='bfill')\n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e0f29cca-5732-4544-af43-34724acea6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.338352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.338352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.338352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.338352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.267437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54.341972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.570259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.429882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.904591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.904591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.937847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55.377426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.338352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54.254055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53.677715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.500359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.500359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34.500359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52.857159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52.300362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52.798550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>51.567722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>34.359352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.359352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.346668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51.323513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>51.782627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52.530678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53.475582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34.115452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>34.115452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>51.861374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   55.338352\n",
       "1   55.338352\n",
       "2   55.338352\n",
       "3   55.338352\n",
       "4   53.267437\n",
       "5   54.341972\n",
       "6   53.570259\n",
       "7   54.429882\n",
       "8   34.904591\n",
       "9   34.904591\n",
       "10  54.937847\n",
       "11  55.377426\n",
       "12  55.338352\n",
       "13  54.254055\n",
       "14  53.677715\n",
       "15  34.500359\n",
       "16  34.500359\n",
       "17  34.500359\n",
       "18  52.857159\n",
       "19  52.300362\n",
       "20  52.798550\n",
       "21  51.567722\n",
       "22  34.359352\n",
       "23  34.359352\n",
       "24  50.346668\n",
       "25  51.323513\n",
       "26  51.782627\n",
       "27  52.530678\n",
       "28  53.475582\n",
       "29  34.115452\n",
       "30  34.115452\n",
       "31  51.861374"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = readPartition('/partitions/PFE_data/PFE_historical_prices json/p1')\n",
    "print(len(ddd))\n",
    "ddd.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1ffb9-58a8-4324-b024-780ed4582958",
   "metadata": {},
   "source": [
    "### Partition-based map and reduce (PMR) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "536ac104-d01a-4ffa-996f-e799b6d84866",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (679650637.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/d4/lgkkv67x3gb4jt3vv_1xlmr40000gn/T/ipykernel_28116/679650637.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return dataframe of re\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Returns dataframe of all data within data range\n",
    "# Returns -1 if no data within given range\n",
    "def mapPartition(partition_content_path, partition_year, partition_month, start_date, end_date):\n",
    "    partition_date = datetime.datetime(partition_year, partition_month, 1)\n",
    "    start_year = start_date.year\n",
    "    start_month = start_date.month\n",
    "    start_day = start_date.day\n",
    "    end_year = end_date.year\n",
    "    end_month = end_date.month\n",
    "    end_day = end_date.day\n",
    "    \n",
    "    partition_results = -1\n",
    "    \n",
    "    # Partition stores data for first month in date range\n",
    "    if (partition_year == start_year) and (partition_month == start_month):\n",
    "        partition_results = readPartition(partition_content_path)\n",
    "        partition_results = partition_results.iloc[]\n",
    "    \n",
    "    # Partition stores data for last month in date range\n",
    "    elif (partition_year == end_year) and (partition_month == end_month):\n",
    "        partition_results = readPartition(partition_content_path)\n",
    "        partition_results = partition_results.iloc[]\n",
    "        \n",
    "    # Partition stores data for middle month in date range\n",
    "    elif (partition_date > start_date) and (partition_date < end_date):\n",
    "        partition_results = readPartition(partition_content_path)\n",
    "    \n",
    "    return partition_results\n",
    "    \n",
    "# Joins and returns all dataframes\n",
    "# Returns -1 if no valid data\n",
    "def reduce(all_partition_results):\n",
    "    reduced_df = -1\n",
    "    \n",
    "    for partition_df in all_partition_results:\n",
    "        if partition_df != -1 and len(partition_df) > 0:\n",
    "            if reduced_df == -1:\n",
    "                reduced_df = partition_df\n",
    "            else:\n",
    "                reduced_df = pd.concat([reduced_df, partition_df])\n",
    "    return reduced_df\n",
    "\n",
    "# Returns dataframe of all data in data range\n",
    "# Returns -1 if no results found\n",
    "def pmf(file_path, start_date, end_date):\n",
    "    all_partitions_data = getPartitionData(file_path)\n",
    "    all_partition_results = []\n",
    "    \n",
    "    for partition_data in all_partitions_data:\n",
    "        location = partition_data[0]\n",
    "        year = partition_data[0]\n",
    "        month = partition_data[0]\n",
    "        partition_results = mapPartition(location, year, month, start_date, end_date)\n",
    "        all_partition_results.append(partition_results)\n",
    "        \n",
    "    return reduce(all_partition_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1b9ab-7351-4468-ab8f-d372829b8fb1",
   "metadata": {},
   "source": [
    "### Demonstrate EDFS functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ee98a-664e-4ddf-8339-a8a938cc5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "edfs_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9153c6-9fcb-4c45-9b71-917c858a8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory('/PFE_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ef5bb40f-f1f1-4ddb-9a1f-629b8cb95d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_file('PFE_historical_prices.json', '/PFE_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3d893-2cda-4673-b261-9c4e4f434439",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory('/country_vacc_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8801811-6633-4e6c-a45d-4880d4855829",
   "metadata": {},
   "outputs": [],
   "source": [
    "for selected_countries_json_files:\n",
    "    put_file(country_vacc_file, '/country_vacc_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450c5ee-4bfc-443f-a9f6-cff04ddcf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file('/PFE_data/PFE_historical_prices.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099215d-22ed-47d9-8644-c9464abcaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory('/PFE_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9d8c6a9d-8a22-4e63-bd6b-0bfe53346393",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_file('PFE_historical_prices.json', '/PFE_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42169954-2297-4d4e-9593-f4a65962ed5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9303398-b12c-42db-87c7-47f3977ccf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d679e86-6907-49b4-8243-291cf327a2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152e711-f313-4326-ac0b-8136b2d78ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b3b57-4535-47c7-9012-65f1408cdefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18904184-6606-4e58-9b2d-1136801f1e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Person3': {'description': 'Eligendi voluptate in nostrum odit. Et voluptas mollitia suscipit. Optio quas ut voluptas.', 'email': 'patience67@gmail.com', 'name': 'Mr. Daryl Leffler Jr.', 'phone': '+1-551-867-7600'}}\n"
     ]
    }
   ],
   "source": [
    "readPartition('/test/test.json', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "725b63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_file('PFE_historical_prices.json', '/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "87813b07-ead8-412b-88e8-0436fc321e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory empty\n"
     ]
    }
   ],
   "source": [
    "remove_file('/test/test json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78b3f331-f56c-4db5-9439-8e21440915c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4mFunctions:\u001b[0m\u001b[0m\n",
      "    \u001b[1mremove_file(path)\u001b[0m \t\t\t Usage example: remove_file('/test/test.json')\n",
      "    \u001b[1mremove_directory(path)\u001b[0m \t\t Usage example: remove_directory('/test/')\n",
      "    \u001b[1mcat_file(path)\u001b[0m \t\t\t Usage example: cat_file('/test/test.json')\n",
      "    \u001b[1mlist_contents(path)\u001b[0m \t\t Usage example: list_contents('/test/')\n",
      "    \u001b[1mmake_directory(path)\u001b[0m \t\t Usage example: make_directory('/test/')\n",
      "    \u001b[1mput_file(file, path)\u001b[0m \t\t Usage example: put_file('test.json', '/test/')\n"
     ]
    }
   ],
   "source": [
    "edfs_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3b63f59-c827-450b-b6f6-15b9de1e3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory('/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3b329582-5da7-4549-ade0-0e023a483893",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_file('test.json', '/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93c3ab3a-1958-4fb2-8250-37cd6ccb3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file('/test/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "012ceb45-54c4-4633-9571-700ad38feb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory('/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924976ae-abd8-4881-9cfb-7cb60741c14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ace5c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFE_historical_prices.json\n"
     ]
    }
   ],
   "source": [
    "list_contents('/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "daca6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"Person1\": {\n",
      "  \"description\": \"Dolor a sit illum vel corrupti est quia. Dolorem repudiandae molestiae qui ut. Repellendus in mollitia error repellat necessitatibus molestiae.\",\n",
      "  \"email\": \"cale83@hotmail.com\",\n",
      "  \"name\": \"Lorenza Nienow\",\n",
      "  \"phone\": \"1-786-677-7753\"\n",
      " },\n",
      " \"Person2\": {\n",
      "  \"description\": \"Amet veniam dolorum dolor sit voluptas. Voluptatem sit amet et provident. Culpa soluta nobis voluptatibus blanditiis animi veritatis officia.\",\n",
      "  \"email\": \"dietrich.janet@gmail.com\",\n",
      "  \"name\": \"Jack Koch PhD\",\n",
      "  \"phone\": \"947.729.3179\"\n",
      " }\n",
      "}\n",
      "{\n",
      " \"Person3\": {\n",
      "  \"description\": \"Eligendi voluptate in nostrum odit. Et voluptas mollitia suscipit. Optio quas ut voluptas.\",\n",
      "  \"email\": \"patience67@gmail.com\",\n",
      "  \"name\": \"Mr. Daryl Leffler Jr.\",\n",
      "  \"phone\": \"+1-551-867-7600\"\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat_file('/test/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d0d7ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFE_historical_prices json\n"
     ]
    }
   ],
   "source": [
    "list_contents('/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7917bcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist\n"
     ]
    }
   ],
   "source": [
    "cat_file('/dummy/dummy.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8c116529",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory('/test2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9fdc2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_file('test.json', '/test2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a552ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file('/test/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10b874af",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file('/test2/test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
